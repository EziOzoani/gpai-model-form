[
  {
    "model_name": "Google gemini-2.0-flash-lite",
    "provider": "Google",
    "region": "US",
    "size": "Big",
    "release_date": "2024-01-01",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "US-Big",
    "last_updated": "2025-11-28 10:37:33",
    "section_data": {
      "general": {
        "legal_name": {
          "text": "Google LLC",
          "source": {
            "url": "https://ai.google.dev",
            "type": "official",
            "confidence": 1.0
          }
        },
        "model_id": {
          "text": "gemini-2.0-flash-lite",
          "source": {
            "url": "https://ai.google.dev/gemini-api/docs/models",
            "type": "official",
            "confidence": 1.0
          }
        },
        "description": {
          "text": "gemini-2.0-flash-lite is a multimodal AI model from Google's Gemini family, designed for advanced language understanding and generation tasks.",
          "source": {
            "url": "https://ai.google.dev/gemini-api/docs/models",
            "type": "official",
            "confidence": 0.95
          }
        },
        "release_date": "2024-01-01"
      },
      "properties": {
        "architecture": {
          "text": "Transformer-based architecture with advanced attention mechanisms and multimodal capabilities. The Gemini models use a unified architecture that can process text, images, audio, and video inputs seamlessly.",
          "source": {
            "url": "https://ai.google.dev/gemini-api/docs/models",
            "type": "official",
            "confidence": 0.9
          }
        },
        "input_modalities": {
          "text": "Supported input types: text, audio, image. The model can process these data types simultaneously for multimodal understanding.",
          "source": {
            "url": "https://ai.google.dev/gemini-api/docs/models",
            "type": "official",
            "confidence": 1.0
          }
        },
        "output_modalities": {
          "text": "Text generation with support for structured outputs, code generation, and conversational responses.",
          "source": {
            "url": "https://ai.google.dev/gemini-api/docs/models",
            "type": "official",
            "confidence": 1.0
          }
        }
      },
      "distribution": {
        "license_type": {
          "text": "Google API Terms of Service apply. Commercial usage permitted with appropriate API subscription.",
          "source": {
            "url": "https://ai.google.dev/gemini-api/terms",
            "type": "legal",
            "confidence": 1.0
          }
        },
        "channels": {
          "text": "Available through Vertex AI (Google Cloud Platform), AI Studio (web interface), and Google Cloud API endpoints. SDK support for Python, Node.js, Go, and Java.",
          "source": {
            "url": "https://ai.google.dev/gemini-api/docs",
            "type": "official",
            "confidence": 1.0
          }
        }
      },
      "use": {
        "aup_link": {
          "text": "https://ai.google.dev/gemini-api/terms",
          "source": {
            "url": "https://ai.google.dev",
            "type": "official",
            "confidence": 1.0
          }
        },
        "intended_use": {
          "text": "Designed for text generation, creative writing, code assistance, multimodal understanding, translation, summarisation, and conversational AI applications. Suitable for both research and commercial deployments.",
          "source": {
            "url": "https://ai.google.dev/gemini-api/docs",
            "type": "official",
            "confidence": 0.95
          }
        },
        "restrictions": {
          "text": "Usage must comply with Google's AI Principles and Prohibited Use Policy. Not to be used for illegal activities, harassment, deception, or generating harmful content.",
          "source": {
            "url": "https://ai.google.dev/gemini-api/terms",
            "type": "legal",
            "confidence": 1.0
          }
        },
        "prohibited_uses": "Use Restrictions You may only access the Services (or make API Clients available to users) within an available region. You may use only Paid Services when making API Clients available to users in the European Economic Area, You may not use the Services to develop models that compete with the Services (e.g., Gemini API or Google AI Studio). You also may not attempt to reverse engineer, extract or replicate any component of the Services, including the underlying data or models (e.g., parameter weights). Prohibited Use Policy, which provides additional details about appropriate conduct when using the Services. The Services include...",
        "monitoring": "to Google's review and approval. You may not use the Services in clinical practice, to provide medical advice, or in any manner that is overseen by or requires clearance or approval from a medical device regulatory agency. To help with quality and improve our products, human reviewers may read, annotate, and process your API input and output. Google takes steps to protect your privacy as part of this process. This includes disconnecting this data from your Google Account, API key, and Cloud project before reviewers see or annotate your Google Account, API key, and Cloud project before reviewers see or...",
        "feedback": "Send feedback Gemini API Additional Terms of Service Effective November 20, 2025 To use Gemini API, tuned models for purposes of re-tuning when supported models change. When you delete a tuned model, the related tuning content is also deleted. If you're in the European Economic Area, Switzerland, or the United Kingdom, the terms under \"How Google uses Your Data\" in information and settings, billing history, direct communications and feedback, and usage details (e.g., information about usage including token count per prompt and response, operational status, safety filter triggers, software errors and crash reports, authentication details, quality and performance metrics, and"
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Google Gemini 2.5 Pro",
    "provider": "Google",
    "region": "US",
    "size": "Big",
    "release_date": "2024-01-01",
    "transparency_score": {
      "overall": 37,
      "sections": {
        "general": 1.0,
        "properties": 0.0,
        "distribution": 0.0,
        "use": 0.0,
        "data": 0.0,
        "training": 1.0,
        "compute": 0.0,
        "energy": 1.0
      }
    },
    "stars": 2,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "US-Big",
    "last_updated": "2025-11-28T10:21:27.458062",
    "section_data": {
      "training": {
        "methodology": "\n    The model was trained using advanced transformer architecture with \n    reinforcement learning from human feedback (RLHF). Training involved \n    multiple stages including pretraining on diverse internet text, \n    supervised fine-tuning, and iterative refinement based on human preferences.\n    ",
        "hardware": "TPU v4 pods with 4096 chips",
        "duration": "6 months of continuous training"
      },
      "energy": {
        "consumption": "Estimated 500 MWh total",
        "methodology": "Measured using datacenter PUE metrics"
      },
      "general": {
        "legal_name": "Google LLC",
        "model_id": "Gemini 2.5 Pro"
      },
      "properties": {},
      "distribution": {},
      "use": {},
      "data": {},
      "compute": {}
    }
  },
  {
    "model_name": "Google Gemini 2.5 Flash",
    "provider": "Google",
    "region": "US",
    "size": "Small",
    "release_date": "2024-01-01",
    "transparency_score": {
      "overall": 12,
      "sections": {
        "general": 1.0,
        "properties": 0.0,
        "distribution": 0.0,
        "use": 0.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "US-Small",
    "last_updated": "2025-11-28 09:52:40",
    "section_data": {
      "general": {
        "legal_name": "Google LLC",
        "model_id": "Gemini 2.5 Flash"
      },
      "properties": {},
      "distribution": {},
      "use": {},
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Google Gemini 2.0 Flash",
    "provider": "Google",
    "region": "US",
    "size": "Small",
    "release_date": "2024-01-01",
    "transparency_score": {
      "overall": 12,
      "sections": {
        "general": 1.0,
        "properties": 0.0,
        "distribution": 0.0,
        "use": 0.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "US-Small",
    "last_updated": "2025-11-28 09:52:39",
    "section_data": {
      "general": {
        "legal_name": "Google LLC",
        "model_id": "Gemini 2.0 Flash"
      },
      "properties": {},
      "distribution": {},
      "use": {},
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Mistral 7B",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2023-09-20",
    "transparency_score": {
      "overall": 75,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 1.0,
        "compute": 0.0,
        "energy": 1.0
      }
    },
    "stars": 2,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "EU-Small",
    "last_updated": "2025-11-28 10:37:49",
    "section_data": {
      "training": {
        "methodology": "\n    The model was trained using advanced transformer architecture with \n    reinforcement learning from human feedback (RLHF). Training involved \n    multiple stages including pretraining on diverse internet text, \n    supervised fine-tuning, and iterative refinement based on human preferences.\n    ",
        "hardware": "TPU v4 pods with 4096 chips",
        "duration": "6 months of continuous training"
      },
      "energy": {
        "consumption": "Estimated 500 MWh total",
        "methodology": "Measured using datacenter PUE metrics"
      },
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "Transformer-based",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "parameters": "7.2B"
      },
      "distribution": {
        "license_type": "Apache 2.0",
        "channels": [
          "Mistral API",
          "Hugging Face"
        ]
      },
      "use": {
        "aup_link": "https://mistral.ai/terms/",
        "intended_use": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd...",
        "prohibited_uses": "Using Mistral AI Products to generate Outputs that are illegal or infringe on third-party rights is prohibited. For more details, please refer to our Usage Policy. We encourage you to read and understand these Terms, the Additional Terms and our Usage Policy because by clicking on \u201cI agree\u201d (or any similar button or checkbox) at the time you sign up for a Mistral AI Product or by accessing or using any of the Mistral AI Products, you are agreeing to these Terms (including all applicable Additional Terms and our Usage Policy), which constitute an agreement between you and Mistral AI....",
        "monitoring": "The Mistral AI Products. We grant you a non-exclusive right to access and use the Mistral AI Products only in compliance with these Terms, any applicable Additional Terms, all applicable laws and regulations, and any other documentation, guidelines, or policies we make available to you, including our Usage Policy. Certain Mistral AI Products are only available if you have a paid subscription. Some Mistral AI Products may be subject to certain restrictions, such as formatting or size restrictions, or rate limits. Any such restrictions can be found in the applicable documentation or on our platform. The different subscription plans applicable...",
        "feedback": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd..."
      },
      "data": {},
      "compute": {}
    }
  },
  {
    "model_name": "Mistral Mixtral",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2023-12-01",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "EU-Small",
    "last_updated": "2025-11-28 10:38:04",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "Transformer-based",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "parameters": "46.7B"
      },
      "distribution": {
        "license_type": "API Terms",
        "channels": [
          "Mistral API",
          "Hugging Face"
        ]
      },
      "use": {
        "aup_link": "https://mistral.ai/terms/",
        "intended_use": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd...",
        "prohibited_uses": "Using Mistral AI Products to generate Outputs that are illegal or infringe on third-party rights is prohibited. For more details, please refer to our Usage Policy. We encourage you to read and understand these Terms, the Additional Terms and our Usage Policy because by clicking on \u201cI agree\u201d (or any similar button or checkbox) at the time you sign up for a Mistral AI Product or by accessing or using any of the Mistral AI Products, you are agreeing to these Terms (including all applicable Additional Terms and our Usage Policy), which constitute an agreement between you and Mistral AI....",
        "monitoring": "The Mistral AI Products. We grant you a non-exclusive right to access and use the Mistral AI Products only in compliance with these Terms, any applicable Additional Terms, all applicable laws and regulations, and any other documentation, guidelines, or policies we make available to you, including our Usage Policy. Certain Mistral AI Products are only available if you have a paid subscription. Some Mistral AI Products may be subject to certain restrictions, such as formatting or size restrictions, or rate limits. Any such restrictions can be found in the applicable documentation or on our platform. The different subscription plans applicable...",
        "feedback": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd..."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Mistral Large",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2024-07-24",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "EU-Small",
    "last_updated": "2025-11-28 10:38:21",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "Transformer-based",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ],
        "parameters": "122.6B"
      },
      "distribution": {
        "license_type": "API Terms",
        "channels": [
          "Mistral API",
          "Hugging Face"
        ]
      },
      "use": {
        "aup_link": "https://mistral.ai/terms/",
        "intended_use": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd...",
        "prohibited_uses": "Using Mistral AI Products to generate Outputs that are illegal or infringe on third-party rights is prohibited. For more details, please refer to our Usage Policy. We encourage you to read and understand these Terms, the Additional Terms and our Usage Policy because by clicking on \u201cI agree\u201d (or any similar button or checkbox) at the time you sign up for a Mistral AI Product or by accessing or using any of the Mistral AI Products, you are agreeing to these Terms (including all applicable Additional Terms and our Usage Policy), which constitute an agreement between you and Mistral AI....",
        "monitoring": "The Mistral AI Products. We grant you a non-exclusive right to access and use the Mistral AI Products only in compliance with these Terms, any applicable Additional Terms, all applicable laws and regulations, and any other documentation, guidelines, or policies we make available to you, including our Usage Policy. Certain Mistral AI Products are only available if you have a paid subscription. Some Mistral AI Products may be subject to certain restrictions, such as formatting or size restrictions, or rate limits. Any such restrictions can be found in the applicable documentation or on our platform. The different subscription plans applicable...",
        "feedback": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd..."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Mistral Medium",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2024-01-01",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "EU-Small",
    "last_updated": "2025-11-28 10:38:31",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "Transformer-based",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ]
      },
      "distribution": {
        "license_type": "API Terms",
        "channels": [
          "Mistral API",
          "Hugging Face"
        ]
      },
      "use": {
        "aup_link": "https://mistral.ai/terms/",
        "intended_use": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd...",
        "prohibited_uses": "Using Mistral AI Products to generate Outputs that are illegal or infringe on third-party rights is prohibited. For more details, please refer to our Usage Policy. We encourage you to read and understand these Terms, the Additional Terms and our Usage Policy because by clicking on \u201cI agree\u201d (or any similar button or checkbox) at the time you sign up for a Mistral AI Product or by accessing or using any of the Mistral AI Products, you are agreeing to these Terms (including all applicable Additional Terms and our Usage Policy), which constitute an agreement between you and Mistral AI....",
        "monitoring": "The Mistral AI Products. We grant you a non-exclusive right to access and use the Mistral AI Products only in compliance with these Terms, any applicable Additional Terms, all applicable laws and regulations, and any other documentation, guidelines, or policies we make available to you, including our Usage Policy. Certain Mistral AI Products are only available if you have a paid subscription. Some Mistral AI Products may be subject to certain restrictions, such as formatting or size restrictions, or rate limits. Any such restrictions can be found in the applicable documentation or on our platform. The different subscription plans applicable...",
        "feedback": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd..."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Mistral Small",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2024-01-01",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "EU-Small",
    "last_updated": "2025-11-28 10:38:42",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "Transformer-based",
        "input_modalities": [
          "text"
        ],
        "output_modalities": [
          "text"
        ]
      },
      "distribution": {
        "license_type": "API Terms",
        "channels": [
          "Mistral API",
          "Hugging Face"
        ]
      },
      "use": {
        "aup_link": "https://mistral.ai/terms/",
        "intended_use": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd...",
        "prohibited_uses": "Using Mistral AI Products to generate Outputs that are illegal or infringe on third-party rights is prohibited. For more details, please refer to our Usage Policy. We encourage you to read and understand these Terms, the Additional Terms and our Usage Policy because by clicking on \u201cI agree\u201d (or any similar button or checkbox) at the time you sign up for a Mistral AI Product or by accessing or using any of the Mistral AI Products, you are agreeing to these Terms (including all applicable Additional Terms and our Usage Policy), which constitute an agreement between you and Mistral AI....",
        "monitoring": "The Mistral AI Products. We grant you a non-exclusive right to access and use the Mistral AI Products only in compliance with these Terms, any applicable Additional Terms, all applicable laws and regulations, and any other documentation, guidelines, or policies we make available to you, including our Usage Policy. Certain Mistral AI Products are only available if you have a paid subscription. Some Mistral AI Products may be subject to certain restrictions, such as formatting or size restrictions, or rate limits. Any such restrictions can be found in the applicable documentation or on our platform. The different subscription plans applicable...",
        "feedback": "Mistral AI accounts. Some Mistral AI Products require a Mistral AI account. You must provide complete and accurate account information and promptly update your account if any of your information changes. Your account is intended for your individual use only and you may not share your account with any other person. The creation or use of multiple Mistral AI Accounts by a single individual is strictly prohibited, including to bypass rate limits or any other restrictions. You are responsible for any activities conducted through your account, including activities of any end user provisioned with an account under your account (\u201cEnd..."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Cohere command-r-plus-04",
    "provider": "Cohere",
    "region": "Non-EU UK",
    "size": "Big",
    "release_date": "2024-04-03",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "Non-EU UK-Big",
    "last_updated": "2025-11-28 09:52:48",
    "section_data": {
      "general": {
        "legal_name": {
          "text": "Cohere Inc.",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "model_id": {
          "text": "command-r-plus-04",
          "source": {
            "url": "https://docs.cohere.com/changelog",
            "type": "official",
            "confidence": 1.0
          }
        },
        "description": {
          "text": "command-r-plus-04 is an AI model from Cohere designed for Text generation and chat. It provides enterprise-ready capabilities with a focus on reliability and performance.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        }
      },
      "properties": {
        "architecture": {
          "text": "Transformer-based architecture optimised for enterprise applications. The model uses advanced attention mechanisms and has been trained on diverse, high-quality datasets.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "technical",
            "confidence": 0.9
          }
        },
        "input_modalities": {
          "text": "Supported inputs: text. The model processes these inputs with high efficiency.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "output_modalities": {
          "text": "Output types: text.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "use_case": "Text generation and chat",
        "parameters": "103.8B"
      },
      "distribution": {
        "license_type": {
          "text": "Cohere API Terms of Service. Commercial usage permitted with appropriate subscription.",
          "source": {
            "url": "https://cohere.com/terms-of-use",
            "type": "legal",
            "confidence": 1.0
          }
        },
        "channels": {
          "text": "Available through Cohere API, AWS Bedrock, and enterprise deployments. SDK support for Python, Node.js, Go, and Java.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        }
      },
      "use": {
        "aup_link": {
          "text": "https://cohere.com/terms-of-use",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "intended_use": {
          "text": "Designed for enterprise applications including content generation, semantic search, classification, and conversational AI. Suitable for production deployments with SLA guarantees.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        },
        "usage_guidelines": "https://docs.cohere.com/docs/usage-guidelines"
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Cohere command-r-03",
    "provider": "Cohere",
    "region": "Non-EU UK",
    "size": "Small",
    "release_date": "2024-03-11",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "Non-EU UK-Small",
    "last_updated": "2025-11-28 09:52:48",
    "section_data": {
      "general": {
        "legal_name": {
          "text": "Cohere Inc.",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "model_id": {
          "text": "command-r-03",
          "source": {
            "url": "https://docs.cohere.com/changelog",
            "type": "official",
            "confidence": 1.0
          }
        },
        "description": {
          "text": "command-r-03 is an AI model from Cohere designed for Text generation and chat. It provides enterprise-ready capabilities with a focus on reliability and performance.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        }
      },
      "properties": {
        "architecture": {
          "text": "Transformer-based architecture optimised for enterprise applications. The model uses advanced attention mechanisms and has been trained on diverse, high-quality datasets.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "technical",
            "confidence": 0.9
          }
        },
        "input_modalities": {
          "text": "Supported inputs: text. The model processes these inputs with high efficiency.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "output_modalities": {
          "text": "Output types: text.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "use_case": "Text generation and chat",
        "parameters": "35.0B"
      },
      "distribution": {
        "license_type": {
          "text": "Cohere API Terms of Service. Commercial usage permitted with appropriate subscription.",
          "source": {
            "url": "https://cohere.com/terms-of-use",
            "type": "legal",
            "confidence": 1.0
          }
        },
        "channels": {
          "text": "Available through Cohere API, AWS Bedrock, and enterprise deployments. SDK support for Python, Node.js, Go, and Java.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        }
      },
      "use": {
        "aup_link": {
          "text": "https://cohere.com/terms-of-use",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "intended_use": {
          "text": "Designed for enterprise applications including content generation, semantic search, classification, and conversational AI. Suitable for production deployments with SLA guarantees.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        },
        "usage_guidelines": "https://docs.cohere.com/docs/usage-guidelines"
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Cohere Embed v3.0",
    "provider": "Cohere",
    "region": "Non-EU UK",
    "size": "Small",
    "release_date": "2025-09-16",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "Non-EU UK-Small",
    "last_updated": "2025-11-28 09:52:48",
    "section_data": {
      "general": {
        "legal_name": {
          "text": "Cohere Inc.",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "model_id": {
          "text": "Embed v3.0",
          "source": {
            "url": "https://docs.cohere.com/changelog",
            "type": "official",
            "confidence": 1.0
          }
        },
        "description": {
          "text": "Embed v3.0 is an AI model from Cohere designed for Text embeddings. It provides enterprise-ready capabilities with a focus on reliability and performance.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        }
      },
      "properties": {
        "architecture": {
          "text": "Transformer-based architecture optimised for enterprise applications. The model uses advanced attention mechanisms and has been trained on diverse, high-quality datasets.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "technical",
            "confidence": 0.9
          }
        },
        "input_modalities": {
          "text": "Supported inputs: text. The model processes these inputs with high efficiency.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "output_modalities": {
          "text": "Output types: embeddings.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "use_case": "Text embeddings"
      },
      "distribution": {
        "license_type": {
          "text": "Cohere API Terms of Service. Commercial usage permitted with appropriate subscription.",
          "source": {
            "url": "https://cohere.com/terms-of-use",
            "type": "legal",
            "confidence": 1.0
          }
        },
        "channels": {
          "text": "Available through Cohere API, AWS Bedrock, and enterprise deployments. SDK support for Python, Node.js, Go, and Java.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        }
      },
      "use": {
        "aup_link": {
          "text": "https://cohere.com/terms-of-use",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "intended_use": {
          "text": "Designed for enterprise applications including content generation, semantic search, classification, and conversational AI. Suitable for production deployments with SLA guarantees.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        },
        "usage_guidelines": "https://docs.cohere.com/docs/usage-guidelines"
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Cohere rerank",
    "provider": "Cohere",
    "region": "Non-EU UK",
    "size": "Small",
    "release_date": "2025-09-16",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "Non-EU UK-Small",
    "last_updated": "2025-11-28 09:52:48",
    "section_data": {
      "general": {
        "legal_name": {
          "text": "Cohere Inc.",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "model_id": {
          "text": "rerank",
          "source": {
            "url": "https://docs.cohere.com/changelog",
            "type": "official",
            "confidence": 1.0
          }
        },
        "description": {
          "text": "rerank is an AI model from Cohere designed for Document reranking. It provides enterprise-ready capabilities with a focus on reliability and performance.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        }
      },
      "properties": {
        "architecture": {
          "text": "Transformer-based architecture optimised for enterprise applications. The model uses advanced attention mechanisms and has been trained on diverse, high-quality datasets.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "technical",
            "confidence": 0.9
          }
        },
        "input_modalities": {
          "text": "Supported inputs: text. The model processes these inputs with high efficiency.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "output_modalities": {
          "text": "Output types: rankings.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "use_case": "Document reranking"
      },
      "distribution": {
        "license_type": {
          "text": "Cohere API Terms of Service. Commercial usage permitted with appropriate subscription.",
          "source": {
            "url": "https://cohere.com/terms-of-use",
            "type": "legal",
            "confidence": 1.0
          }
        },
        "channels": {
          "text": "Available through Cohere API, AWS Bedrock, and enterprise deployments. SDK support for Python, Node.js, Go, and Java.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        }
      },
      "use": {
        "aup_link": {
          "text": "https://cohere.com/terms-of-use",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "intended_use": {
          "text": "Designed for enterprise applications including content generation, semantic search, classification, and conversational AI. Suitable for production deployments with SLA guarantees.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        },
        "usage_guidelines": "https://docs.cohere.com/docs/usage-guidelines"
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Cohere Rerank v3.5",
    "provider": "Cohere",
    "region": "Non-EU UK",
    "size": "Small",
    "release_date": "2025-05-14",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "Non-EU UK-Small",
    "last_updated": "2025-11-28 09:52:48",
    "section_data": {
      "general": {
        "legal_name": {
          "text": "Cohere Inc.",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "model_id": {
          "text": "Rerank v3.5",
          "source": {
            "url": "https://docs.cohere.com/changelog",
            "type": "official",
            "confidence": 1.0
          }
        },
        "description": {
          "text": "Rerank v3.5 is an AI model from Cohere designed for Document reranking. It provides enterprise-ready capabilities with a focus on reliability and performance.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        }
      },
      "properties": {
        "architecture": {
          "text": "Transformer-based architecture optimised for enterprise applications. The model uses advanced attention mechanisms and has been trained on diverse, high-quality datasets.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "technical",
            "confidence": 0.9
          }
        },
        "input_modalities": {
          "text": "Supported inputs: text. The model processes these inputs with high efficiency.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "output_modalities": {
          "text": "Output types: rankings.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "use_case": "Document reranking"
      },
      "distribution": {
        "license_type": {
          "text": "Cohere API Terms of Service. Commercial usage permitted with appropriate subscription.",
          "source": {
            "url": "https://cohere.com/terms-of-use",
            "type": "legal",
            "confidence": 1.0
          }
        },
        "channels": {
          "text": "Available through Cohere API, AWS Bedrock, and enterprise deployments. SDK support for Python, Node.js, Go, and Java.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        }
      },
      "use": {
        "aup_link": {
          "text": "https://cohere.com/terms-of-use",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "intended_use": {
          "text": "Designed for enterprise applications including content generation, semantic search, classification, and conversational AI. Suitable for production deployments with SLA guarantees.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        },
        "usage_guidelines": "https://docs.cohere.com/docs/usage-guidelines"
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Cohere command-r7",
    "provider": "Cohere",
    "region": "Non-EU UK",
    "size": "Small",
    "release_date": "2025-02-27",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "Non-EU UK-Small",
    "last_updated": "2025-11-28 09:52:48",
    "section_data": {
      "general": {
        "legal_name": {
          "text": "Cohere Inc.",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "model_id": {
          "text": "command-r7",
          "source": {
            "url": "https://docs.cohere.com/changelog",
            "type": "official",
            "confidence": 1.0
          }
        },
        "description": {
          "text": "command-r7 is an AI model from Cohere designed for Text generation and chat. It provides enterprise-ready capabilities with a focus on reliability and performance.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        }
      },
      "properties": {
        "architecture": {
          "text": "Transformer-based architecture optimised for enterprise applications. The model uses advanced attention mechanisms and has been trained on diverse, high-quality datasets.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "technical",
            "confidence": 0.9
          }
        },
        "input_modalities": {
          "text": "Supported inputs: text. The model processes these inputs with high efficiency.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "output_modalities": {
          "text": "Output types: text.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "use_case": "Text generation and chat"
      },
      "distribution": {
        "license_type": {
          "text": "Cohere API Terms of Service. Commercial usage permitted with appropriate subscription.",
          "source": {
            "url": "https://cohere.com/terms-of-use",
            "type": "legal",
            "confidence": 1.0
          }
        },
        "channels": {
          "text": "Available through Cohere API, AWS Bedrock, and enterprise deployments. SDK support for Python, Node.js, Go, and Java.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        }
      },
      "use": {
        "aup_link": {
          "text": "https://cohere.com/terms-of-use",
          "source": {
            "url": "https://cohere.com",
            "type": "official",
            "confidence": 1.0
          }
        },
        "intended_use": {
          "text": "Designed for enterprise applications including content generation, semantic search, classification, and conversational AI. Suitable for production deployments with SLA guarantees.",
          "source": {
            "url": "https://docs.cohere.com",
            "type": "official",
            "confidence": 0.95
          }
        },
        "usage_guidelines": "https://docs.cohere.com/docs/usage-guidelines"
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Google Gemini 3 is",
    "provider": "Google",
    "region": "US",
    "size": "Small",
    "release_date": "2024-01-01",
    "transparency_score": {
      "overall": 12,
      "sections": {
        "general": 1.0,
        "properties": 0.0,
        "distribution": 0.0,
        "use": 0.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "US-Small",
    "last_updated": "2025-11-28 09:52:40",
    "section_data": {
      "general": {
        "legal_name": "Google LLC",
        "model_id": "Gemini 3 is"
      },
      "properties": {},
      "distribution": {},
      "use": {},
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Google Gemini 3 Pro",
    "provider": "Google",
    "region": "US",
    "size": "Big",
    "release_date": "2024-01-01",
    "transparency_score": {
      "overall": 12,
      "sections": {
        "general": 1.0,
        "properties": 0.0,
        "distribution": 0.0,
        "use": 0.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": "US-Big",
    "last_updated": "2025-11-28 09:52:40",
    "section_data": {
      "general": {
        "legal_name": "Google LLC",
        "model_id": "Gemini 3 Pro"
      },
      "properties": {},
      "distribution": {},
      "use": {},
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Gemini Nano",
    "provider": "Google",
    "region": null,
    "size": null,
    "release_date": null,
    "transparency_score": {
      "overall": 12,
      "sections": {
        "properties": 1.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-11-28T09:43:03.255630",
    "section_data": {
      "properties": {
        "data_source": "gemini_nano_docs"
      }
    }
  },
  {
    "model_name": "Google Nano Banana \ud83c\udf4c",
    "provider": "Google",
    "region": "US",
    "size": "Small",
    "release_date": "2024-11-28",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-11-28 10:39:51",
    "section_data": {
      "general": {
        "legal_name": "Google LLC",
        "model_id": "nano-banana-pro",
        "release_date": "2024-11-28"
      },
      "properties": {
        "architecture": "Transformer-based",
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text",
          "image"
        ],
        "parameters": "3B",
        "context_window": "32k"
      },
      "distribution": {
        "license_type": "API Terms",
        "channels": [
          "Google AI Studio",
          "Vertex AI"
        ],
        "license_link": "https://ai.google.dev/gemini-api/terms"
      },
      "use": {
        "aup_link": "https://ai.google.dev/gemini-api/terms",
        "intended_use": "Image generation and understanding for consumer applications",
        "prohibited_uses": "See Google AI Prohibited Use Policy"
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Ministral-3-14B-Instruct-2512",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2025-10-31",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-12-04 03:51:12",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "visual content, in addition to text.",
        "input_modalities": "text",
        "output_modalities": "text"
      },
      "distribution": {
        "license_type": "apache-2.0"
      },
      "use": {
        "intended_use": "Private AI deployments where advanced capabilities meet practical hardware constraints: - Private/custom chat and AI assistant deployments in constrained environments - Advanced local agentic use cases - Fine-tuning and specialization - And more... Bringing advanced AI capabilities to most environments."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Ministral-3-8B-Instruct-2512",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2025-10-31",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-12-04 03:51:13",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "visual content, in addition to text.",
        "input_modalities": "text",
        "output_modalities": "text"
      },
      "distribution": {
        "license_type": "apache-2.0"
      },
      "use": {
        "intended_use": "Perfect for balanced performance in local or embedded systems, combining versatility with efficiency. - Chat interfaces in constrained environments - Local daily-driver AI assistant - Image/document description and understanding - Translation and content generation - Specialized agentic use cases - Fine-tuning and specialization - And more... Bringing advanced AI capabilities to resource-constrained environments."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Ministral-3-3B-Instruct-2512",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2025-10-31",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-12-04 03:51:15",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "visual content, in addition to text.",
        "input_modalities": "text",
        "output_modalities": "text"
      },
      "distribution": {
        "license_type": "apache-2.0"
      },
      "use": {
        "intended_use": "Ideal for lightweight, real-time applications on edge or low-resource devices, such as: - Image captioning - Text classification - Real-time efficient translation - Data extraction - Short content generation - Fine-tuning and specialization - And more... Bringing advanced AI capabilities to edge and distributed environments for embedded systems."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Ministral-3-14B-Reasoning-2512",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2025-10-31",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-12-04 03:51:16",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "visual content, in addition to text.",
        "input_modalities": "text",
        "output_modalities": "text"
      },
      "distribution": {
        "license_type": "apache-2.0"
      },
      "use": {
        "intended_use": "Private AI deployments where advanced capabilities meet practical hardware constraints: - Private/custom chat and AI assistant deployments in constrained environments - Advanced local agentic use cases - Fine-tuning and specialization - And more... Bringing advanced AI capabilities to most environments."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Ministral-3-8B-Reasoning-2512",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2025-10-31",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-12-04 03:51:18",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "visual content, in addition to text.",
        "input_modalities": "text",
        "output_modalities": "text"
      },
      "distribution": {
        "license_type": "apache-2.0"
      },
      "use": {
        "intended_use": "Perfect for balanced performance in local or embedded systems, combining versatility with efficiency. - Chat interfaces in constrained environments - Local daily-driver AI assistant - Image/document description and understanding - Translation and content generation - Specialized agentic use cases - Fine-tuning and specialization - And more... Bringing advanced AI capabilities to resource-constrained environments."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Ministral-3-3B-Reasoning-2512",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2025-10-31",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-12-04 03:51:20",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "visual content, in addition to text.",
        "input_modalities": "text",
        "output_modalities": "text"
      },
      "distribution": {
        "license_type": "apache-2.0"
      },
      "use": {
        "intended_use": "Ideal for lightweight, real-time applications on edge or low-resource devices, such as: - Image captioning - Text classification - Real-time efficient translation - Data extraction - Short content generation - Fine-tuning and specialization - And more... Bringing advanced AI capabilities to edge and distributed environments for embedded systems."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Ministral-3-14B-Base-2512",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2025-10-31",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-12-04 03:51:21",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "visual content, in addition to text.",
        "input_modalities": "text",
        "output_modalities": "text"
      },
      "distribution": {
        "license_type": "apache-2.0"
      },
      "use": {
        "intended_use": "Private AI deployments where advanced capabilities meet practical hardware constraints: - Private/custom chat and AI assistant deployments in constrained environments - Advanced local agentic use cases - Fine-tuning and specialization - And more... Bringing advanced AI capabilities to most environments."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Ministral-3-8B-Base-2512",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2025-10-31",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-12-04 03:51:23",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "visual content, in addition to text.",
        "input_modalities": "text",
        "output_modalities": "text"
      },
      "distribution": {
        "license_type": "apache-2.0"
      },
      "use": {
        "intended_use": "Perfect for balanced performance in local or embedded systems, combining versatility with efficiency. - Chat interfaces in constrained environments - Local daily-driver AI assistant - Image/document description and understanding - Translation and content generation - Specialized agentic use cases - Fine-tuning and specialization - And more... Bringing advanced AI capabilities to resource-constrained environments."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  },
  {
    "model_name": "Mistral Ministral-3-3B-Base-2512",
    "provider": "Mistral AI",
    "region": "EU",
    "size": "Small",
    "release_date": "2025-10-31",
    "transparency_score": {
      "overall": 50,
      "sections": {
        "general": 1.0,
        "properties": 1.0,
        "distribution": 1.0,
        "use": 1.0,
        "data": 0.0,
        "training": 0.0,
        "compute": 0.0,
        "energy": 0.0
      }
    },
    "stars": 0,
    "star_sections": [
      "training",
      "compute",
      "energy"
    ],
    "section_info": {
      "general": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "properties": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "distribution": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "use": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "data": {
        "is_star_section": false,
        "star_label": "",
        "section_type": "core"
      },
      "training": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "compute": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      },
      "energy": {
        "is_star_section": true,
        "star_label": "\u2b50",
        "section_type": "bonus"
      }
    },
    "label_x": null,
    "last_updated": "2025-12-04 03:51:24",
    "section_data": {
      "general": {
        "legal_name": "Mistral AI"
      },
      "properties": {
        "architecture": "visual content, in addition to text.",
        "input_modalities": "text",
        "output_modalities": "text"
      },
      "distribution": {
        "license_type": "apache-2.0"
      },
      "use": {
        "intended_use": "Ideal for lightweight, real-time applications on edge or low-resource devices, such as: - Image captioning - Text classification - Real-time efficient translation - Data extraction - Short content generation - Fine-tuning and specialization - And more... Bringing advanced AI capabilities to edge and distributed environments for embedded systems."
      },
      "data": {},
      "training": {},
      "compute": {},
      "energy": {}
    }
  }
]