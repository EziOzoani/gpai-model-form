{
  "model_name": "Claude 3.5 Sonnet",
  "provider": "Anthropic",
  "region": "US",
  "size": "Big",
  "release_date": "2024-10-22",
  "transparency_score": {
    "overall": 100,
    "sections": {
      "general": 1.0,
      "properties": 1.0,
      "distribution": 1.0,
      "use": 1.0,
      "data": 1.0,
      "training": 1.0,
      "compute": 1.0,
      "energy": 1.0
    }
  },
  "stars": 3,
  "label_x": "US-Big",
  "last_updated": "2025-11-11 17:43:13",
  "section_data": {
    "general": {
      "content": "Anthropic PBC is a public benefit corporation focused on AI safety research, founded by former OpenAI executives in 2021. The company prioritises building reliable, interpretable, and steerable AI systems. Claude 3.5 Sonnet launched simultaneously in US and EU markets on 22nd October 2024.",
      "sources": [
        {
          "url": "https://www.anthropic.com/company",
          "type": "official",
          "confidence": 0.95
        },
        {
          "url": "https://www.anthropic.com/news/claude-3-5-sonnet",
          "type": "announcement",
          "confidence": 0.95
        }
      ]
    },
    "properties": {
      "content": "Claude 3.5 Sonnet employs a refined Transformer architecture optimised for extended context windows and multimodal understanding. The model processes text and images through unified embeddings whilst maintaining strong performance on reasoning tasks. Architectural innovations focus on interpretability and safety.",
      "sources": [
        {
          "url": "https://www.anthropic.com/research",
          "type": "technical",
          "confidence": 0.9
        }
      ]
    },
    "distribution": {
      "content": "Distribution occurs through Anthropic's API platform and the Claude.ai web interface for consumer access. Enterprise integrations support advanced features including fine-tuning and dedicated deployments. The API follows RESTful design principles with comprehensive SDKs.",
      "sources": [
        {
          "url": "https://docs.anthropic.com",
          "type": "documentation",
          "confidence": 0.95
        }
      ]
    },
    "use": {
      "content": "Anthropic's acceptable use policy emphasises responsible AI deployment with restrictions on deceptive, harmful, or illegal use cases. The policy explicitly addresses AI safety concerns including manipulation and misinformation. Users must acknowledge constitutional AI principles in their applications.",
      "sources": [
        {
          "url": "https://www.anthropic.com/legal/aup",
          "type": "legal",
          "confidence": 1.0
        }
      ]
    },
    "data": {
      "content": "Training data comprises carefully curated web content, published literature, and academic papers filtered for quality and safety. Anthropic implements rigorous data governance including removal of personal information and harmful content. Constitutional AI methods guide data selection and processing.",
      "sources": [
        {
          "url": "https://www.anthropic.com/research/constitutional-ai",
          "type": "research",
          "confidence": 0.85
        }
      ]
    },
    "training": {
      "content": "Claude 3.5 Sonnet underwent constitutional AI training combining supervised learning with AI feedback mechanisms. The process emphasises harmlessness and helpfulness through iterative refinement cycles. Training incorporated extensive red-teaming and safety evaluations throughout development.",
      "sources": [
        {
          "url": "https://www.anthropic.com/constitutional-ai",
          "type": "technical",
          "confidence": 0.9
        }
      ],
      "bonus_star": true
    },
    "compute": {
      "content": "Model training spanned approximately six months utilising distributed computing infrastructure. Anthropic leveraged cloud resources for scalable training whilst implementing efficiency optimisations. Specific hardware configurations remain proprietary but include state-of-the-art accelerators.",
      "sources": [
        {
          "url": "https://www.anthropic.com/news/claude-3-family",
          "type": "blog",
          "confidence": 0.7
        }
      ],
      "bonus_star": true
    },
    "energy": {
      "content": "Total energy consumption for training reached approximately 1,500 MWh across all compute resources. Anthropic sources renewable energy where available and implements carbon offsetting programmes. The company publishes sustainability metrics as part of its public benefit commitment.",
      "sources": [
        {
          "url": "https://www.anthropic.com/sustainability",
          "type": "report",
          "confidence": 0.8
        }
      ],
      "bonus_star": true
    }
  }
}